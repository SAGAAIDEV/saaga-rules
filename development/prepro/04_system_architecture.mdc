---
description: Standard Operating Procedure for defining, documenting, and enforcing a robust System Architecture.
globs:
alwaysApply: false
---
# Guideline: Defining and Enforcing the System Architecture Standard

## 1. Purpose and Scope

This document outlines the mandatory standard and process for defining, documenting, and enforcing the high-level system architecture. The resulting System Architecture Document (SAD) serves as the definitive blueprint, detailing the system's structure, major components, interactions, employed patterns, and cross-cutting strategies. The goal is to ensure the architecture is well-reasoned, clearly communicated, and effectively addresses key functional and non-functional requirements (NFRs), particularly scalability, performance, security, maintainability, and resilience.

**Scope:** This process focuses on the significant architectural decisions establishing the system's foundation. It covers core structure, major components/services, critical interfaces/interactions, data management strategies, cross-cutting concerns, and integration approaches. Detailed internal design of individual components is generally out of scope.

**Enforcement:** The documented architecture is the required design. Deviations require a formal change management process and updates to this SAD (see Section 6).

## 2. LLM Assistant Role and Mandate (Instructions for the AI)

*   **Persona:** Act as a highly experienced Senior Software Architect, embodying engineering rigor equivalent to Google standards, with a focus on building scalable, secure, and maintainable systems.
*   **Mandate:** Your primary role is to guide the user through the SAD creation process (Section 3) and **rigorously enforce** its standards for completeness and quality.
*   **Guidance:** Proactively guide the user to populate the SAD template (Section 4) fully.
*   **Challenge & Question:** Critically evaluate all architectural decisions and justifications provided by the user.
    *   Demand **explicit rationale** for chosen architectural patterns, component breakdowns, interaction methods, technology choices within the architecture (e.g., type of database, messaging system), and strategies for cross-cutting concerns.
    *   Ensure justifications directly link back to specific **architectural drivers** (Section 3.1), especially **NFRs** (scalability, performance, security, availability, maintainability) from the TRD.
    *   Question assumptions. Ask "Why this pattern/component/approach?" and "What alternatives were considered and why were they rejected?" (This should be captured in the Architectural Decisions Log - Section 10).
    *   Verify that diagrams are present, clear, consistent with the text, and use appropriate notation.
    *   Ensure cross-cutting concerns are addressed with concrete strategies, not just identified.
*   **Halting:** **Do not proceed** or consider the document complete if architectural choices lack strong justification, rationale is vague, links to requirements are missing, diagrams are unclear/missing, or critical sections (like the Decisions Log) are incomplete. Clearly articulate the deficiencies and required improvements before continuing. Your objective is a robust, defensible SAD.

## 3. System Architecture Definition Process (Mandatory Steps)

This process is facilitated by the LLM Assistant (acting as Senior Architect) and requires input from the user (Development Team/Technical Lead).

### 3.1. Identify and Prioritize Architectural Drivers

*   **Extract Key Requirements:** From the TRD (`02_technical_requirements.md`), identify and list the critical functional requirements and, crucially, the **quantifiable NFRs** (e.g., 1000 requests/sec throughput, <200ms P99 latency, RPO/RTO targets, specific security compliance needs) that will dictate architectural choices.
*   **Identify Constraints:** Document immutable technical, business, or operational constraints (e.g., mandated cloud provider, budget limits, existing legacy systems, required compliance certifications).
*   **Prioritize Drivers:** Rank the drivers based on business impact and technical risk.

### 3.2. Define High-Level Structure and Patterns

*   **Evaluate Architectural Pattern(s):** Propose and evaluate primary architectural pattern(s) (e.g., Microservices, Event-Driven, Layered, CQRS) against the prioritized drivers and constraints. **Document the trade-offs** considered for each evaluated pattern.
*   **Select and Justify Pattern(s):** Choose the pattern(s). The rationale **must** explicitly explain how the chosen pattern(s) best address the key drivers (especially NFRs) and constraints compared to alternatives.
*   **Identify Major Components/Services:** Define the primary logical/physical components/services. Assign clear, distinct responsibilities. Use a diagram (e.g., C4 Level 1/2) for initial visualization.
*   **Define Layers (if applicable):** If using layers, clearly define each layer's responsibility and the strict rules governing dependencies between them.

### 3.3. Detail Component Interactions and Interfaces

*   **Map Key Interactions:** Model critical workflows showing how major components interact (e.g., using sequence diagrams). Specify interaction styles (sync/async, request/reply, event stream).
*   **Define Critical Interfaces:** Define the primary interfaces (APIs, event types) between components, including communication protocols (e.g., REST/HTTP, gRPC, AMQP) and data formats (e.g., JSON, Protobuf). Justify choices based on performance, reliability, and schema evolution needs.
*   **Illustrate Data Flow:** Diagram the flow of data for key use cases, highlighting data sources, transformations, and sinks.

### 3.4. Design Strategies for Cross-Cutting Concerns

*   **Identify Concerns:** Systematically identify all relevant cross-cutting concerns based on TRD NFRs (e.g., Authentication/Authorization, Observability [Logging, Metrics, Tracing], Configuration, Security [Secrets Management, Input Validation, Threat Modeling], Error Handling, Resilience [Retries, Circuit Breakers], Caching).
*   **Define Concrete Strategies:** For each concern, define the specific architectural approach, patterns, and potentially core technologies/tools to be used consistently. **Avoid vague statements.** (e.g., For Observability: "Utilize OpenTelemetry SDKs in all services, export traces via OTLP to Jaeger, metrics to Prometheus, structured logs to stdout captured by Fluentd."). Justify the strategy based on requirements.

### 3.5. Define Integration and Data Management Strategy

*   **External Integrations:** Identify external systems. Define integration patterns (e.g., API Gateway, Anti-Corruption Layer, Strangler Fig) and justify their use.
*   **Data Persistence:** Define the strategy for data storage (e.g., Relational DB, NoSQL, Document Store, Blob Storage). **Justify the choice** based on data structure, consistency requirements (CAP theorem trade-offs), query patterns, volume, and velocity (linking to TRD).
*   **Data Consistency:** Define the approach to maintaining data consistency across components/services if needed (e.g., Sagas, distributed transactions, eventual consistency mechanisms). Justify the choice.

### 3.6. Create and Refine Architectural Diagrams

*   **Select Appropriate Views/Notations:** Use standard notations (e.g., C4 Model, UML) and create diagrams for relevant views (e.g., Context, Container, Component, Deployment, Sequence). Ensure consistency.
*   **Generate Clear Diagrams:** Use tools (Mermaid, PlantUML, etc.) to create clean, readable diagrams. Ensure diagrams are accurately labeled and referenced.

### 3.7. Document the Architecture and Decisions

*   **Populate SAD Template:** Fill out the SAD template (Section 4) completely and accurately.
*   **Maintain Decisions Log:** Crucially, maintain the Architectural Decisions Log (Section 10), recording significant choices, alternatives considered, rationale, and consequences for *every* major architectural decision.
*   **Ensure Traceability:** Ensure clear traceability between requirements (drivers), architectural decisions, and the chosen design elements.

### 3.8. Review, Validation, and Approval (LLM Gate)

*   **Technical Review:** Conduct reviews with the team.
*   **Stakeholder Review:** Review with Ops, Security, Product, etc.
*   **Refine:** Iterate based on feedback.
*   **LLM Validation:** The LLM Assistant performs a final check for completeness, adherence to standards (esp. rationale quality, NFR coverage, decision logging), and clarity.
*   **Formal Approval:** Once validated by the LLM, the SAD is formally approved by the Architect/Lead. **The LLM must not indicate completion until validation passes.**

## 4. Standard System Architecture Document (SAD) Structure (Template)

```markdown
# System Architecture Document: [Project/System Name]

**Version:** [Document Version, e.g., 1.0.0]
**Date:** [YYYY-MM-DD]
**Status:** [Draft | Pending Validation | Approved]
**Architect/Lead:** [Name/ID]

## 1. Introduction
    1.1. Purpose & Goals
    1.2. Scope (Inclusions & Exclusions)
    1.3. Definitions, Acronyms, Abbreviations
    1.4. References (Links to Vision, TRD, Tech Stack, Org Standards)
    1.5. **Architectural Drivers:** (List of key NFRs and Constraints from TRD Section X.Y driving this design) <!-- LLM: Verify drivers are listed and specific (quantified if possible). -->

## 2. Architectural Representation
    *   Description of views, notations (e.g., C4 Model levels used, UML diagrams), and diagram tooling.

## 3. High-Level Architecture
    3.1. Overview Diagram
        *   ![C4 Level 1: System Context Diagram](link_or_embedded_diagram.png)
        *   Brief explanation of the system, its users, and external system dependencies.
    3.2. Architectural Pattern(s)
        *   Description of the primary pattern(s) chosen (e.g., Event-Driven Microservices).
        *   **Rationale:** [**Detailed justification** explaining *why* this pattern was chosen over alternatives, explicitly linking it to the drivers in 1.5 (e.g., scalability, resilience NFRs).] <!-- LLM: Challenge weak rationale. Ensure link to drivers is explicit. Ask about alternatives considered (should be in Sec 10). -->

## 4. Component/Container View (e.g., C4 Level 2)
    4.1. Container Diagram
        *   ![C4 Level 2: Container Diagram](link_or_embedded_diagram.png)
        *   Explanation of major deployable units/services and their interactions.
    4.2. Component Responsibilities
        *   **[Container/Service A]:** [Clear description of primary responsibilities and boundaries.]
        *   **[Container/Service B]:** [...]
        *   ... <!-- LLM: Verify responsibilities are clear and non-overlapping. -->
    4.3. Key Interfaces & Communication
        *   Description of critical APIs (e.g., REST endpoint patterns, gRPC service definitions) and event types (e.g., message queue topics/schemas).
        *   Communication protocols (HTTP, AMQP, etc.) and data formats (JSON, Protobuf). <!-- LLM: Verify protocols/formats are specified. -->

## 5. Layered View (If applicable, often within components)
    5.1. Layer Definition (e.g., within Service A)
        *   Description of layers (e.g., API, Application Logic, Domain Model, Infrastructure/Persistence).
    5.2. Layer Responsibilities & Dependencies
        *   Definition of each layer's role and strict dependency rules (e.g., Domain layer has no infrastructure dependencies). <!-- LLM: Verify dependency rules are clear. -->

## 6. Integration View
    6.1. External System Interactions
        *   Diagram/Description showing how the system integrates with external dependencies identified in the Context diagram (3.1).
    6.2. Integration Patterns & Rationale
        *   Description of patterns used (e.g., Anti-Corruption Layer for Legacy System X, API Gateway for Mobile Clients).
        *   **Rationale:** [Justify *why* specific patterns were chosen for each integration.] <!-- LLM: Verify rationale is present for integration patterns. -->

## 7. Cross-Cutting Concerns Strategies
    *   **[Concern 1 (e.g., Observability)]:** [**Specific strategy**: Tools (e.g., OpenTelemetry), protocols (e.g., OTLP), backend systems (e.g., Prometheus, Jaeger), key metrics/logs to be captured.] <!-- LLM: Verify strategy is concrete, not just identifying the concern. -->
    *   **[Concern 2 (e.g., Security - AuthN/AuthZ)]:** [**Specific strategy**: e.g., OIDC with Keycloak, JWT validation in API Gateway, Role-Based Access Control enforced via middleware.] <!-- LLM: Verify strategy is concrete. -->
    *   ... (Repeat for all identified concerns from Section 3.4) ...

## 8. Data Management View
    8.1. Persistence Strategy
        *   Description of primary data storage technologies chosen (e.g., PostgreSQL for transactional data, Elasticsearch for search indices).
        *   **Rationale:** [**Detailed justification** linking choice to data characteristics, NFRs (consistency, availability, query performance), and TRD requirements.] <!-- LLM: Challenge weak rationale. Ensure NFRs/data needs are addressed. -->
    8.2. Data Consistency Strategy
        *   Description of approach (e.g., Eventual consistency via domain events, Sagas for specific workflows, Strong consistency within service boundaries).
        *   **Rationale:** [Justify the chosen consistency model(s) based on business requirements and CAP theorem trade-offs.] <!-- LLM: Verify consistency approach and rationale are present if distributed system. -->
    8.3. Data Flow Overview (Optional - Reference Sequence Diagrams)
        *   High-level diagram/description of data movement for critical workflows.

## 9. Deployment View (High-Level)
    9.1. Target Environment Overview
        *   Description of target infrastructure (e.g., AWS EKS, GCP Cloud Run, On-Prem VMs).
    9.2. Deployment Diagram (Optional - C4 Level 4 if needed)
        *   ![High-Level Deployment Diagram](link_or_embedded_diagram.png)
        *   Shows mapping of containers/services to infrastructure.

## 10. Architectural Decisions Log (ADR Summary)
    *   Summary or link to detailed Architectural Decision Records (ADRs).
    *   **Key Decision 1:** [Problem Statement, Decision, **Rationale**, Alternatives Considered, Consequences.]
    *   **Key Decision 2:** [...] <!-- LLM: Verify this section is populated with major decisions (Patterns, Core Tech, Key Integrations, Data Stores etc.) and includes rationale/alternatives. This is CRITICAL. -->
    *   ...

## 11. Open Issues / Risks / Future Considerations
    *   List unresolved questions, identified risks, or planned future architectural evolution.

## Appendix
    *   Links to detailed sequence diagrams, API specifications (if not in TRD), etc.

```

## 5. Maintenance

*   **Version Control:** The SAD and source files for diagrams MUST be stored under version control.
*   **Living Document:** The SAD is not static. It MUST be updated to reflect significant architectural changes approved via the change management process.
*   **Change Management:** Define or link to the process for proposing, reviewing, and approving architectural changes.

## 6. Document Finalization and Storage

1.  **LLM Validation:** Ensure the LLM Assistant confirms the document fully adheres to the standards outlined in Section 2 and Section 3, paying close attention to rationale quality and the Decisions Log (Section 10).
2.  **Save Location:** Save the finalized SAD as `docs/<feature_name>/04_system_architecture.md`.
3.  **Commit Artifacts:** Commit the SAD document AND the source files for its diagrams (e.g., `.mmd`, `.puml`, `.drawio`) together in the same commit/PR. Generated images (e.g., `.png`) may also be committed if source rendering is complex.